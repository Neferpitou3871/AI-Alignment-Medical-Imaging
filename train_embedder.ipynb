{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhr_k\\anaconda3\\envs\\medfusion\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import ConcatDataset\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime \n",
    "#\n",
    "from medical_diffusion.data.datamodules import SimpleDataModule\n",
    "from medical_diffusion.data.datasets import CXPDataset_Loader, CXPDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:134075|val:44134|test:44584\n"
     ]
    }
   ],
   "source": [
    "# --------------- Settings --------------------\n",
    "current_time = datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "path_run_dir = Path.cwd() / 'runs' / str(current_time)\n",
    "path_run_dir.mkdir(parents=True, exist_ok=True)\n",
    "gpus = [0] if torch.cuda.is_available() else None\n",
    "\n",
    "\n",
    "dataset = CXPDataset_Loader(root_dir = r\"C:\\Users\\mhr_k\\Data\\CheXpert-Simp\", windows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = CXPDataset(data_list = dataset.train_ds)\n",
    "ds_val = CXPDataset(data_list = dataset.val_ds)\n",
    "ds_test = CXPDataset(data_list = dataset.test_ds)\n",
    "\n",
    "dm = SimpleDataModule(\n",
    "    ds_train = ds_train,\n",
    "    ds_val = ds_val,\n",
    "    batch_size=8, \n",
    "    # num_workers=0,\n",
    "    pin_memory=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = CXPDataset(image_resize = 64, data_list = dataset.train_ds[:100])\n",
    "ds_val = CXPDataset(image_resize = 64, data_list = dataset.val_ds[:10])\n",
    "ds_test = CXPDataset(image_resize = 64, data_list = dataset.test_ds[:10])\n",
    "\n",
    "dm = SimpleDataModule(\n",
    "    ds_train = ds_train,\n",
    "    ds_val = ds_val,\n",
    "    ds_test = ds_test,\n",
    "    batch_size=8, \n",
    "    # num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': tensor([[[-0.9765, -0.5922, -0.6235,  ..., -0.9922, -0.9922, -0.9922],\n",
       "          [-0.9451, -0.6078, -0.5686,  ..., -0.9922, -0.9922, -0.9922],\n",
       "          [-1.0000, -0.6706, -0.6078,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          ...,\n",
       "          [ 0.2706,  0.2941,  0.3333,  ...,  0.8745,  0.8588,  0.8431],\n",
       "          [ 0.3333,  0.3569,  0.3882,  ...,  0.8588,  0.8510,  0.8353],\n",
       "          [ 0.3804,  0.3961,  0.4275,  ...,  0.8431,  0.8353,  0.8275]]]),\n",
       " 'target': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medical_diffusion.models.embedders.latent_embedders import VQVAE, VQGAN, VAE, VAEGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torchvision.transforms.functional as tF\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import TensorDataset, Subset\n",
    "\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity as LPIPS\n",
    "from torchmetrics.functional import multiscale_structural_similarity_index_measure as mmssim\n",
    "\n",
    "from medical_diffusion.models.embedders.latent_embedders import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [baseline] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    }
   ],
   "source": [
    "model = VAE(\n",
    "        in_channels=1, \n",
    "        out_channels=1, \n",
    "        emb_channels=8,\n",
    "        spatial_dims=2,\n",
    "        hid_chs =    [ 64, 128, 256,  512], \n",
    "        kernel_sizes=[ 3,  3,   3,    3],\n",
    "        strides =    [ 1,  2,   2,    2],\n",
    "        deep_supervision=1,\n",
    "        use_attention= 'none',\n",
    "        loss = torch.nn.MSELoss,\n",
    "        # optimizer_kwargs={'lr':1e-6},\n",
    "        embedding_loss_weight=1e-6\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\mhr_k\\anaconda3\\envs\\medfusion\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:608: UserWarning: Checkpoint directory c:\\Users\\mhr_k\\OneDrive\\Documents\\AI-Research\\code\\medfusion\\runs\\2024_03_12_201723 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name      | Type                         | Params\n",
      "-----------------------------------------------------------\n",
      "0 | loss_fct  | MSELoss                      | 0     \n",
      "1 | perceiver | LPIPS                        | 14.7 M\n",
      "2 | inc       | UnetResBlock                 | 38.0 K\n",
      "3 | encoders  | ModuleList                   | 7.7 M \n",
      "4 | out_enc   | Sequential                   | 74.0 K\n",
      "5 | quantizer | DiagonalGaussianDistribution | 0     \n",
      "6 | inc_dec   | UnetResBlock                 | 2.4 M \n",
      "7 | decoders  | ModuleList                   | 3.1 M \n",
      "8 | outc      | BasicBlock                   | 65    \n",
      "9 | outc_ver  | ModuleList                   | 129   \n",
      "-----------------------------------------------------------\n",
      "13.4 M    Trainable params\n",
      "14.7 M    Non-trainable params\n",
      "28.1 M    Total params\n",
      "112.312   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 12/12 [10:02<00:00, 50.24s/it, loss=2.2e+04, v_num=1]   \n"
     ]
    }
   ],
   "source": [
    "to_monitor = \"train/L1\"  # \"val/loss\" \n",
    "min_max = \"min\"\n",
    "save_and_sample_every = 4\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0, # minimum change in the monitored quantity to qualify as an improvement\n",
    "    patience=30, # number of checks with no improvement\n",
    "    mode=min_max\n",
    ")\n",
    "checkpointing = ModelCheckpoint(\n",
    "    dirpath=str(path_run_dir), # dirpath\n",
    "    monitor=\"val/loss\",\n",
    "    every_n_train_steps=save_and_sample_every,\n",
    "    save_last=True,\n",
    "    save_top_k=5,\n",
    "    mode=min_max,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    accelerator='cpu',\n",
    "    devices=1,\n",
    "    # precision=16,\n",
    "    # amp_backend='apex',\n",
    "    # amp_level='O2',\n",
    "    # gradient_clip_val=0.5,\n",
    "    default_root_dir=str(path_run_dir),\n",
    "    callbacks=[checkpointing],\n",
    "    # callbacks=[checkpointing, early_stopping],\n",
    "    enable_checkpointing=True,\n",
    "    check_val_every_n_epoch=1,\n",
    "    log_every_n_steps=save_and_sample_every, \n",
    "    auto_lr_find=False,\n",
    "    # limit_train_batches=1000,\n",
    "    limit_val_batches=50, # 0 = disable validation - Note: Early Stopping no longer available \n",
    "    min_epochs=2,\n",
    "    max_epochs=5,\n",
    "    num_sanity_val_steps=2,\n",
    ")\n",
    "\n",
    "# ---------------- Execute Training ----------------\n",
    "trainer.fit(model, datamodule=dm)\n",
    "\n",
    "# ------------- Save path to best model -------------\n",
    "model.save_best_checkpoint(trainer.logger.log_dir, checkpointing.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
